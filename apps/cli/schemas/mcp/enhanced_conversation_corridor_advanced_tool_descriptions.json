{
  "conversation_store": "游릭 **RECOMMENDED** Store the current conversation for future context. Use this to preserve important discussions for later recall.\n\n**WHEN TO USE:**\n- After completing significant implementation work with valuable discussion\n- When user asks: \"save this conversation\", \"remember this discussion\", \"store this for later\"\n- After solving complex problems that involved back-and-forth problem solving\n- When onboarding discussions contain important project context or decisions\n- Before ending a session that produced valuable insights or learnings\n- Examples: \"save this debugging session\", \"remember how we implemented auth\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse automatically after completing multi-turn implementations, debugging sessions, or architectural discussions that generated significant value. When a conversation contains important learnings, decisions, or problem-solving patterns, store it proactively before the session ends. This creates searchable conversation history for future context retrieval. Consider pairing with conversation_extract to automatically generate learnings from stored conversations.\n\n**BEST FOR:**\nPreserving valuable conversation threads for future reference. Enables conversation_search and conversation_extract workflows. Creates audit trail of how decisions and solutions were reached.\n\n**PARAMETERS:**\n- summary: Concise 1-2 sentence summary of conversation topic and outcome (REQUIRED)\n- messages: Array of message objects with role ('user', 'assistant', 'system') and content (REQUIRED)\n- agentType: Type of AI agent (e.g., 'claude-code', 'cursor', 'copilot')\n- sessionId: Optional session ID to link related conversations",

  "conversation_search": "游릭 **RECOMMENDED** Search past conversations by summary or content.\n\n**WHEN TO USE:**\n- When user asks: \"did we discuss X before?\", \"find the conversation about Y\", \"what did we say about Z?\"\n- Before starting work on similar problems to check for prior discussions\n- When user references past work but doesn't remember specifics\n- When looking for context about how past decisions were made\n- Examples: \"find our auth discussion\", \"when did we talk about caching?\", \"show past API design conversations\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse proactively when the user's question suggests prior relevant discussions. Before solving a problem, check if similar conversations exist to provide continuity and avoid repeating work. When a user mentions \"we did this before\" or \"last time\", automatically search to retrieve that context. This ensures consistency across sessions.\n\n**BEST FOR:**\nRetrieving past discussion context and decision-making history. Finding similar problems previously solved. Maintaining continuity across multiple sessions.\n\n**PARAMETERS:**\n- query: Search query to match against conversation summaries and content\n- sessionId: Filter by specific session ID to find related conversations\n- limit: Maximum results to return (default: 10)",

  "conversation_extract": "游릭 **RECOMMENDED** Extract ideas, decisions, and learnings from a stored conversation using AI analysis. Automatically stores extracted records in the memory.\n\n**WHEN TO USE:**\n- After storing a valuable conversation with conversation_store\n- When user asks: \"extract learnings from that discussion\", \"what did we decide in that conversation?\", \"pull ideas from our chat\"\n- After complex problem-solving sessions to capture insights automatically\n- When converting conversational knowledge into structured memory\n- Examples: \"extract from our architecture discussion\", \"get decisions from debugging session\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse automatically after storing important conversations to transform unstructured dialogue into structured learnings, decisions, and ideas. When conversation_store is called for significant sessions, follow up with extraction to populate the memory system. This automates knowledge capture from natural dialogue. The AI analyzes conversation patterns to identify: learnings (\"TIL...\", \"we discovered...\"), decisions (\"let's use...\", \"we chose...\"), and ideas (\"what if...\", \"we could...\").\n\n**BEST FOR:**\nAutomated knowledge mining from conversations. Converts dialogue into actionable memory records. Reduces manual effort to capture insights from discussions.\n\n**PARAMETERS:**\n- conversationId: ID of the stored conversation to extract from (e.g., 'conv_abc123') (REQUIRED)",

  "corridor_learnings": "游릭 **RECOMMENDED** Get personal learnings from the global corridor (cross-workspace knowledge).\n\n**WHEN TO USE:**\n- When starting work in a new workspace to check for transferable knowledge\n- When user asks: \"what have I learned about X across all projects?\", \"show my global learnings\", \"any patterns I've seen before?\"\n- Before solving problems to leverage insights from other workspaces\n- When encountering similar patterns, technologies, or challenges\n- Examples: \"corridor learnings about auth\", \"what do I know about React globally?\", \"show my API design learnings\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse proactively when working in new workspaces or encountering problems that may have been solved elsewhere. Before attempting solutions, check corridor for cross-workspace insights. When the user mentions technologies or patterns common across projects, automatically retrieve corridor learnings to provide informed context. This leverages institutional memory across all your work.\n\n**BEST FOR:**\nCross-workspace knowledge transfer. Applying lessons learned in one project to another. Building personal knowledge base that transcends individual workspaces. Avoiding repeating mistakes across projects.\n\n**PARAMETERS:**\n- query: Optional search query to filter corridor learnings by content\n- limit: Maximum learnings to return (default: 20)",

  "corridor_promote": "游릭 **RECOMMENDED** Promote a workspace learning to the personal corridor for cross-workspace use.\n\n**WHEN TO USE:**\n- After discovering generally applicable learnings not specific to one workspace\n- When user asks: \"save this globally\", \"promote this learning to corridor\", \"I'll need this in other projects\"\n- When a learning applies to technology, patterns, or practices used across projects\n- When documenting best practices or gotchas that transcend workspaces\n- Examples: \"promote this React learning\", \"save this API pattern globally\", \"add to my personal knowledge base\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse automatically when storing learnings that are technology-specific or pattern-based rather than workspace-specific. If a learning mentions general technologies (React, PostgreSQL, Docker) or universal patterns (auth, caching, error handling), suggest promotion to corridor. Before promoting, ensure the learning isn't workspace-specific (e.g., doesn't reference specific file paths or project-unique architecture).\n\n**BEST FOR:**\nBuilding reusable knowledge base across all work. Identifying portable insights worth carrying to other projects. Creating personal \"lessons learned\" library.\n\n**PARAMETERS:**\n- learningId: ID of the workspace learning to promote to corridor (e.g., 'l_abc123') (REQUIRED)",

  "corridor_reinforce": "游릭 **RECOMMENDED** Increase confidence for a personal corridor learning (marks it as useful).\n\n**WHEN TO USE:**\n- When a corridor learning proves useful in a new workspace\n- When user asks: \"mark this learning as valuable\", \"reinforce this corridor knowledge\", \"this was helpful\"\n- After applying a corridor learning successfully to solve a problem\n- When validating that a global learning is still accurate and relevant\n- Examples: \"reinforce this auth learning\", \"mark this as confirmed\", \"boost confidence\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse automatically when retrieving and successfully applying corridor learnings to new situations. When a corridor learning is recalled and helps solve a problem, reinforce it to increase confidence. This creates a feedback loop where useful knowledge becomes stronger over time. Track which corridor learnings are applied and reinforce them after successful use.\n\n**BEST FOR:**\nConfidence calibration for cross-workspace knowledge. Identifying which global learnings are most valuable. Creating virtuous cycle of knowledge validation.\n\n**PARAMETERS:**\n- learningId: ID of the corridor learning to reinforce (REQUIRED)",

  "corridor_links": "游릭 **RECOMMENDED** Get all linked workspaces in the global corridor.\n\n**WHEN TO USE:**\n- When user asks: \"what workspaces are in my corridor?\", \"show my linked projects\", \"which projects share knowledge?\"\n- When exploring the scope of cross-workspace knowledge sharing\n- When auditing or managing corridor configuration\n- When understanding the network of workspace connections\n- Examples: \"show corridor workspaces\", \"what projects am I linking?\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse when the user needs to understand corridor scope or when debugging corridor behavior. If corridor learnings seem unexpected or missing, check corridor_links to verify workspace connections. This is primarily informational for understanding the corridor system state.\n\n**BEST FOR:**\nAuditing corridor configuration. Understanding which workspaces contribute to global knowledge. Debugging corridor behavior.\n\n**PARAMETERS:**\nNone - returns complete list of linked workspaces.",

  "corridor_stats": "游릭 **RECOMMENDED** Get statistics about the personal corridor (learning count, linked workspaces).\n\n**WHEN TO USE:**\n- When user asks: \"show corridor stats\", \"how much is in my corridor?\", \"corridor overview\"\n- When monitoring growth of cross-workspace knowledge base\n- When deciding whether to use corridor features more actively\n- When reporting on personal knowledge accumulation\n- Examples: \"how many corridor learnings?\", \"show my global knowledge stats\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse when providing corridor feature overviews or when the user is exploring corridor capabilities. If the user is new to corridors, show stats to demonstrate the value of cross-workspace knowledge sharing. This helps users understand the scale and utility of their corridor.\n\n**BEST FOR:**\nOverview of corridor system state. Monitoring knowledge base growth. Understanding corridor usage patterns.\n\n**PARAMETERS:**\nNone - returns statistics about corridor learnings and linked workspaces.",

  "search_semantic": "游릭 **RECOMMENDED** Perform semantic search using AI embeddings. Finds conceptually similar content even without exact word matches. Requires embedding backend to be configured.\n\n**WHEN TO USE:**\n- When exact keyword search fails to find relevant results\n- When user asks conceptual questions: \"find anything about error patterns\", \"show learnings related to performance\"\n- When searching for related ideas/decisions without knowing exact terminology\n- When exploring thematically similar content across different vocabulary\n- Examples: \"find authentication-related decisions\" (matches OAuth, JWT, sessions, login)\n\n**AUTONOMOUS BEHAVIOR:**\nUse when keyword search would be too restrictive or when the user's intent is conceptual rather than literal. If a standard search query seems conceptual (\"performance issues\", \"security patterns\"), automatically use semantic search for better results. This finds related content even when exact words don't match. Fall back to keyword search if embeddings are not configured.\n\n**BEST FOR:**\nConceptual discovery and thematic exploration. Finding related content across different terminology. Better recall when you don't know exact keywords. Requires embedding backend to be configured.\n\n**PARAMETERS:**\n- query: Natural language query describing concepts (e.g., 'error handling patterns', 'authentication best practices') (REQUIRED)\n- kinds: Filter by record types - 'idea', 'decision', 'learning' (default: all kinds)\n- limit: Maximum results to return (default: 10)\n- minSimilarity: Similarity threshold 0.0-1.0 (default: 0.5) - higher = more strict\n- scope: Filter by scope - 'palace', 'room', 'file'\n- scopePath: Filter by scope path (room name or file path)",

  "search_hybrid": "游릭 **RECOMMENDED** Combined keyword + semantic search. Returns results matching either exact words or conceptual meaning. Falls back to keyword-only if embeddings are not configured.\n\n**WHEN TO USE:**\n- When you want best of both worlds: exact matches AND conceptually similar results\n- When user asks: \"find everything about X\" where X could have exact or related matches\n- When unsure whether to use keyword or semantic search\n- When you want comprehensive results with both precision and recall\n- Examples: \"find auth\" (returns exact \"auth\" + OAuth, JWT, authentication, login)\n\n**AUTONOMOUS BEHAVIOR:**\nUse as the default search method when you need comprehensive results. Hybrid search combines the precision of keyword matching with the recall of semantic search. This is the safest choice when search strategy is ambiguous. Returns exact matches first, then semantically similar content, giving users the most complete result set.\n\n**BEST FOR:**\nGeneral-purpose search with maximum coverage. Default choice when search strategy is unclear. Combines benefits of keyword and semantic approaches. Gracefully degrades to keyword-only if embeddings unavailable.\n\n**PARAMETERS:**\n- query: Search query - can be keywords or natural language (REQUIRED)\n- kinds: Filter by record types - 'idea', 'decision', 'learning' (default: all kinds)\n- limit: Maximum results to return (default: 10)",

  "search_similar": "游릭 **RECOMMENDED** Find records similar to a given record ID. Uses semantic similarity to find related content.\n\n**WHEN TO USE:**\n- When user asks: \"find similar ideas\", \"what else is like this?\", \"show related decisions\"\n- After viewing a learning/decision/idea and wanting to explore related content\n- When building clusters of related knowledge around a topic\n- When exploring thematic connections between records\n- Examples: \"find similar learnings to l_abc123\", \"what's related to this decision?\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse after presenting a record to the user to proactively suggest related content. When a learning or decision is recalled, automatically find similar records to provide additional context. This creates exploratory browsing patterns and surfaces related knowledge the user might not know to search for. Useful for \"if you liked this, you might also be interested in...\" workflows.\n\n**BEST FOR:**\nExploration and discovery of related content. Building knowledge clusters around themes. Surfacing related insights user might not think to search for. Requires embeddings to be configured.\n\n**PARAMETERS:**\n- recordId: ID of the record to find similar content for (e.g., 'l_abc123', 'i_xyz789', 'd_abc456') (REQUIRED)\n- limit: Maximum results to return (default: 5)\n- minSimilarity: Similarity threshold 0.0-1.0 (default: 0.6) - higher = more similar",

  "embedding_sync": "游릭 **RECOMMENDED** Generate embeddings for records that don't have them. Useful for backfilling after enabling embeddings or after bulk imports.\n\n**WHEN TO USE:**\n- After first enabling embedding backend in configuration\n- When user asks: \"sync embeddings\", \"generate missing embeddings\", \"backfill embeddings\"\n- After bulk imports of learnings/decisions/ideas from external sources\n- When embedding_stats shows many pending records\n- When semantic search is newly available and historical records need processing\n- Examples: \"embed all records\", \"sync semantic search\", \"process pending embeddings\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse automatically after detecting that embeddings are newly enabled but many records lack them. When embedding_stats shows significant pending count, suggest and potentially auto-run sync. This is typically a one-time or periodic maintenance operation. Don't run excessively as it consumes LLM API calls for embedding generation.\n\n**BEST FOR:**\nMaintenance and setup of semantic search infrastructure. Backfilling embeddings after configuration changes. Ensuring semantic search has complete coverage.\n\n**PARAMETERS:**\n- kinds: Record types to process - 'idea', 'decision', 'learning' (default: all kinds)\n- limit: Maximum records to process per run (default: 100) - use to rate limit API calls",

  "embedding_stats": "游릭 **RECOMMENDED** Get statistics about the embedding system including total embeddings, pending records, and pipeline status.\n\n**WHEN TO USE:**\n- When user asks: \"show embedding stats\", \"how many embeddings?\", \"semantic search status\"\n- Before running embedding_sync to see how much work is needed\n- When debugging why semantic search isn't returning expected results\n- When monitoring embedding system health and coverage\n- Examples: \"check embedding coverage\", \"show semantic search status\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse when the user is exploring semantic search capabilities or when debugging search results. If semantic search seems incomplete or broken, check embedding_stats to diagnose. Also useful before suggesting embedding_sync to show the user the backlog size. This is primarily informational.\n\n**BEST FOR:**\nMonitoring embedding system state. Diagnosing semantic search issues. Understanding coverage and pending work. Deciding when to run embedding_sync.\n\n**PARAMETERS:**\nNone - returns statistics about embeddings, pending records, and system status.",

  "decay_stats": "游릭 **RECOMMENDED** Get statistics about confidence decay for learnings (at-risk count, decayed count, averages).\n\n**WHEN TO USE:**\n- When user asks: \"show decay stats\", \"which learnings are decaying?\", \"learning health overview\"\n- Before running decay_apply to understand impact\n- When monitoring learning quality and usage patterns\n- When deciding whether to enable or adjust decay policies\n- Examples: \"show stale learnings\", \"what's at risk?\", \"decay overview\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse periodically (e.g., weekly) to monitor learning health and surface at-risk knowledge. If stats show many learnings with very low confidence, suggest reviewing or cleaning them up. This helps maintain a high-quality knowledge base by surfacing unused learnings that may need reinforcement or archival.\n\n**BEST FOR:**\nMonitoring learning lifecycle health. Understanding which learnings are unused. Deciding when to apply or prevent decay. Maintaining knowledge quality.\n\n**PARAMETERS:**\nNone - returns statistics about decay state, at-risk learnings, and averages.",

  "decay_preview": "游릭 **RECOMMENDED** Preview what learnings would be affected by applying decay. Does not modify anything.\n\n**WHEN TO USE:**\n- Before running decay_apply to see what will change\n- When user asks: \"what would decay affect?\", \"preview decay\", \"show me what would be decayed\"\n- When deciding whether to reinforce learnings before they decay\n- When understanding decay policy impact on current knowledge base\n- Examples: \"preview next decay run\", \"what's about to decay?\", \"show me at-risk learnings\"\n\n**AUTONOMOUS BEHAVIOR:**\nAlways run decay_preview before running decay_apply to show the user what will change. When decay_stats shows high at-risk counts, proactively preview to help user decide whether to apply decay or reinforce learnings. This is a safe, read-only operation that helps informed decision-making.\n\n**BEST FOR:**\nSafe preview of decay impact before applying. Decision support for decay management. Identifying learnings that need reinforcement.\n\n**PARAMETERS:**\n- limit: Maximum records to show in preview (default: 20)",

  "decay_apply": "游릭 **RECOMMENDED** Apply confidence decay to inactive learnings. Reduces confidence of learnings that haven't been accessed.\n\n**WHEN TO USE:**\n- When user explicitly asks: \"apply decay\", \"reduce confidence of stale learnings\", \"run decay\"\n- After reviewing decay_preview and deciding to proceed\n- As periodic maintenance to keep learning quality high\n- When cleaning up knowledge base by lowering confidence of unused learnings\n- Examples: \"decay inactive learnings\", \"apply confidence decay\"\n\n**AUTONOMOUS BEHAVIOR:**\nNever run automatically without user confirmation - this modifies learning confidence. Always show decay_preview first, then ask for confirmation before running decay_apply. This is a destructive operation that should be intentional. Use sparingly and with user awareness. After applying, suggest using decay_boost or decay_reinforce to restore important learnings if needed.\n\n**BEST FOR:**\nMaintaining knowledge quality by reducing confidence of unused learnings. Automatic cleanup of stale knowledge. Requires explicit user intent - don't run autonomously.\n\n**PARAMETERS:**\nNone - applies decay to all eligible learnings based on access patterns and time.",

  "decay_reinforce": "游릭 **RECOMMENDED** Reinforce a learning to prevent decay (marks it as recently accessed).\n\n**WHEN TO USE:**\n- When a learning proves still valuable despite not being accessed recently\n- When user asks: \"prevent this from decaying\", \"reinforce this learning\", \"mark as active\"\n- After decay_preview shows important learnings at risk\n- When a learning is manually reviewed and confirmed still relevant\n- Examples: \"reinforce l_abc123\", \"prevent decay on this learning\", \"keep this fresh\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse automatically when retrieving and using learnings to mark them as accessed. Whenever a learning contributes to solving a problem or answering a question, reinforce it to signal it's still valuable. This creates a natural feedback loop where useful learnings stay strong. Combine with decay_preview to proactively reinforce important at-risk learnings.\n\n**BEST FOR:**\nPreventing valuable learnings from decaying. Marking learnings as recently accessed. Creating feedback loop for learning utility. Maintaining confidence of important knowledge.\n\n**PARAMETERS:**\n- learningId: ID of the learning to reinforce (e.g., 'l_abc123') (REQUIRED)",

  "decay_boost": "游릭 **RECOMMENDED** Boost a learning's confidence (opposite of decay).\n\n**WHEN TO USE:**\n- When a learning proves particularly valuable or accurate\n- When user asks: \"boost this learning\", \"increase confidence\", \"mark as highly valuable\"\n- After a learning helps solve a difficult problem\n- When manually verifying a learning is still correct and important\n- Examples: \"boost l_abc123\", \"increase confidence by 0.2\", \"mark as very important\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse when a learning is exceptionally helpful in solving problems. If a learning is the key to solving a difficult issue, boost its confidence beyond just reinforcement. This signals high-value knowledge that should be prioritized in future retrievals. Use sparingly - most cases should use decay_reinforce; boost is for truly exceptional value.\n\n**BEST FOR:**\nRewarding exceptionally valuable learnings. Increasing confidence of verified important knowledge. Creating hierarchy of learning importance. Recovering from excessive decay.\n\n**PARAMETERS:**\n- learningId: ID of the learning to boost (e.g., 'l_abc123') (REQUIRED)\n- amount: Amount to boost confidence, 0.0-1.0 (default: 0.1) - larger boosts for higher value",

  "scope_explain": "游릭 **RECOMMENDED** Explain the scope inheritance chain for a file. Shows which learnings/decisions apply at each scope level (file, room, palace, corridor).\n\n**WHEN TO USE:**\n- When user asks: \"what applies to this file?\", \"explain scope for X\", \"show inheritance chain\"\n- When debugging why certain learnings appear or don't appear for a file\n- When understanding how scope-based filtering works\n- When teaching or explaining the scope system to users\n- Examples: \"explain scope for auth/handler.go\", \"what rules apply here?\", \"show scope chain\"\n\n**AUTONOMOUS BEHAVIOR:**\nUse when the user is confused about which learnings/decisions apply to a file. If context_auto_inject results seem unexpected, run scope_explain to show the inheritance chain. This is primarily educational/debugging - it helps users understand the scope system. Also useful when deciding at which scope level to store new learnings.\n\n**BEST FOR:**\nEducation about scope system. Debugging scope-based context injection. Understanding inheritance patterns. Deciding where to store new learnings.\n\n**PARAMETERS:**\n- file_path: File path to explain scope inheritance for (REQUIRED)"
}
